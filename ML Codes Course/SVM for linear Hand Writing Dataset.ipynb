{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Recognizing hand-written digits\n",
    "\n",
    "\n",
    "An example showing how the scikit-learn can be used to recognize images of\n",
    "hand-written digits.\n",
    "\n",
    "This example is commented in the\n",
    ":ref:`tutorial section of the user manual <introduction>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chhavi/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAChCAYAAADTPlYDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f522faa5b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "print(digits.images.shape)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(kernel = 'linear',gamma=0.05, C = 5)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(data, digits.target, test_size = 0.2)\n",
    "#classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "classifier.fit(X_train, Y_train)\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = Y_test\n",
    "predicted = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980555555556\n",
      "Classification report for classifier SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.05, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        37\n",
      "          1       1.00      0.96      0.98        27\n",
      "          2       1.00      1.00      1.00        36\n",
      "          3       0.94      0.94      0.94        36\n",
      "          4       1.00      1.00      1.00        30\n",
      "          5       0.98      1.00      0.99        42\n",
      "          6       1.00      1.00      1.00        39\n",
      "          7       0.98      1.00      0.99        40\n",
      "          8       0.97      0.91      0.94        35\n",
      "          9       0.95      0.97      0.96        38\n",
      "\n",
      "avg / total       0.98      0.98      0.98       360\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 26  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 36  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 34  0  1  0  0  0  1]\n",
      " [ 0  0  0  0 30  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 39  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  0]\n",
      " [ 0  0  0  2  0  0  0  1 32  0]\n",
      " [ 0  0  0  0  0  0  0  0  1 37]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(X_test, Y_test))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(kernel = 'rbf')\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(data, digits.target, test_size = 0.2)\n",
    "#classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "classifier.fit(X_train, Y_train)\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = Y_test\n",
    "predicted = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.73        40\n",
      "          1       1.00      0.59      0.74        29\n",
      "          2       0.13      1.00      0.23        27\n",
      "          3       1.00      0.65      0.79        37\n",
      "          4       1.00      0.41      0.58        37\n",
      "          5       1.00      0.70      0.83        37\n",
      "          6       1.00      0.53      0.69        36\n",
      "          7       1.00      0.45      0.62        33\n",
      "          8       1.00      0.02      0.04        44\n",
      "          9       1.00      0.33      0.49        40\n",
      "\n",
      "avg / total       0.93      0.50      0.57       360\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[23  0 17  0  0  0  0  0  0  0]\n",
      " [ 0 17 12  0  0  0  0  0  0  0]\n",
      " [ 0  0 27  0  0  0  0  0  0  0]\n",
      " [ 0  0 13 24  0  0  0  0  0  0]\n",
      " [ 0  0 22  0 15  0  0  0  0  0]\n",
      " [ 0  0 11  0  0 26  0  0  0  0]\n",
      " [ 0  0 17  0  0  0 19  0  0  0]\n",
      " [ 0  0 18  0  0  0  0 15  0  0]\n",
      " [ 0  0 43  0  0  0  0  0  1  0]\n",
      " [ 0  0 27  0  0  0  0  0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(X_test, Y_test))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "RFC = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RFC.fit(X_train, Y_train)\n",
    "#RFC.score(X_test, Y_test)\n",
    "expected = Y_test\n",
    "predicted = RFC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955555555556\n",
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        40\n",
      "          1       0.88      0.97      0.92        29\n",
      "          2       0.96      1.00      0.98        27\n",
      "          3       1.00      0.92      0.96        37\n",
      "          4       1.00      0.97      0.99        37\n",
      "          5       0.88      1.00      0.94        37\n",
      "          6       0.97      0.97      0.97        36\n",
      "          7       0.97      0.97      0.97        33\n",
      "          8       0.97      0.86      0.92        44\n",
      "          9       0.97      0.93      0.95        40\n",
      "\n",
      "avg / total       0.96      0.96      0.96       360\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[40  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 27  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 34  0  2  1  0  0  0]\n",
      " [ 0  0  0  0 36  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 37  0  0  0  0]\n",
      " [ 1  0  0  0  0  0 35  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 32  0  0]\n",
      " [ 1  3  1  0  0  0  0  0 38  1]\n",
      " [ 0  1  0  0  0  2  0  0  0 37]]\n"
     ]
    }
   ],
   "source": [
    "print(RFC.score(X_test, Y_test))\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Repeat with KNN classifer as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
